{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set API Keys in Environment Variables\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDw6YNJSiSjpNwZVu5wjCsx8ywVjpYnziY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
    "    model= 'gemini-2.0-flash-exp',\n",
    "    api_key= os.environ[\"GOOGLE_API_KEY\"],\n",
    "    temperature=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell me about this {product} and why its useful?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm = model, prompt = prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, let's talk about the iPhone 13 and why it's still a useful and relevant phone in today's market. While it's not the newest iPhone, it offers a great balance of features, performance, and price.\\n\\n**Here's a breakdown of what makes the iPhone 13 useful:**\\n\\n**1. Excellent Performance:**\\n\\n* **A15 Bionic Chip:** The iPhone 13 is powered by Apple's A15 Bionic chip. This chip is incredibly powerful and handles everyday tasks, demanding apps, and even graphically intensive games with ease. You'll experience smooth multitasking, fast app loading, and a generally responsive experience.\\n* **Future-Proofing:** While not the absolute latest chip, the A15 is still very capable and will likely remain so for several years. This means you won't feel the need to upgrade as quickly as you might with a phone using an older processor.\\n\\n**2. Impressive Camera System:**\\n\\n* **Dual 12MP Rear Cameras:** The iPhone 13 features a dual-camera system with a wide and ultrawide lens. These cameras capture excellent photos and videos in various lighting conditions.\\n* **Sensor-Shift Optical Image Stabilization:** This technology helps reduce blur and shake, resulting in sharper images and smoother videos, especially in low light.\\n* **Cinematic Mode:** This feature allows you to record videos with a shallow depth of field, creating a professional-looking cinematic effect.\\n* **Photographic Styles:** You can customize the look of your photos with different photographic styles, giving you more creative control.\\n* **Great for Social Media:** The camera system is perfect for capturing and sharing high-quality photos and videos on social media platforms.\\n\\n**3. Beautiful Display:**\\n\\n* **Super Retina XDR Display:** The iPhone 13 boasts a vibrant and sharp Super Retina XDR display. Colors are accurate, blacks are deep, and the display is bright enough to be easily visible even in direct sunlight.\\n* **OLED Technology:** The OLED technology provides excellent contrast and viewing angles, making it a pleasure to consume content on the phone.\\n* **True Tone:** This feature automatically adjusts the display's color temperature to match your ambient lighting, making it more comfortable to look at.\\n\\n**4. Solid Battery Life:**\\n\\n* **Improved Battery:** The iPhone 13 offers a noticeable improvement in battery life compared to its predecessor. You can typically get through a full day of moderate use on a single charge.\\n* **Fast Charging:** The phone supports fast charging, allowing you to quickly top up the battery when needed.\\n\\n**5. Durable and Well-Built:**\\n\\n* **Ceramic Shield Front Cover:** The front of the phone is protected by Apple's Ceramic Shield, which is more durable and resistant to scratches and drops than traditional glass.\\n* **IP68 Water and Dust Resistance:** The iPhone 13 is rated IP68 for water and dust resistance, meaning it can withstand being submerged in water for a short period.\\n\\n**6. Ecosystem and Software:**\\n\\n* **iOS Ecosystem:** The iPhone 13 runs on Apple's iOS operating system, which is known for its user-friendliness, security, and regular software updates.\\n* **App Store:** You have access to the vast and well-curated App Store, offering a wide range of apps for various purposes.\\n* **Seamless Integration:** The iPhone 13 integrates seamlessly with other Apple devices and services, such as AirPods, Apple Watch, and iCloud.\\n\\n**Why is it still useful?**\\n\\n* **Value for Money:** The iPhone 13 is often available at a lower price than the newer models, making it a great value proposition for those who don't need the absolute latest features.\\n* **Long-Term Support:** Apple provides software updates for its iPhones for several years, ensuring that the iPhone 13 will continue to receive new features and security patches.\\n* **Reliable Performance:** The A15 chip is still very powerful and will handle most tasks with ease for years to come.\\n* **Excellent Camera:** The camera system is still among the best in the smartphone market, allowing you to capture high-quality photos and videos.\\n\\n**Who is the iPhone 13 good for?**\\n\\n* **People who want a high-quality smartphone without paying top dollar for the latest model.**\\n* **Users who value a great camera, smooth performance, and a reliable operating system.**\\n* **Those who are already invested in the Apple ecosystem.**\\n* **Anyone looking for a phone that will last them for several years.**\\n\\n**In conclusion, the iPhone 13 is still a very useful and capable smartphone in 2024. It offers a great balance of performance, features, and price, making it a compelling option for many users.**\\n\\nDo you have any specific questions about the iPhone 13 that I can answer for you? Perhaps you're wondering about a specific feature or comparing it to another phone? Let me know!\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"iPhone 13\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prompt = ChatPromptTemplate.from_template(\"Tell me the brand name of this {product}\")\n",
    "\n",
    "chain_1 = LLMChain(llm = model, prompt = first_prompt)\n",
    "\n",
    "\n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_template(\"Write a 20 words description for the following \\\n",
    "    company:{company_name}\")\n",
    "\n",
    "chain_2 = LLMChain(llm = model, prompt = second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chains = SimpleSequentialChain(chains = [chain_1, chain_2], verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mThe brand name of an iPhone 13 is **Apple**.\n",
      "\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mApple: Innovating technology with the iPhone 13, seamlessly blending power, design, and user experience for a connected world.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Apple: Innovating technology with the iPhone 13, seamlessly blending power, design, and user experience for a connected world.\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_chains.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Ahmed',\n",
       " 'Greetings': 'Okay, here are a few options for a personalized hello to Mr. Ahmed, depending on the context and your relationship with him:\\n\\n**Formal:**\\n\\n*   \"Good morning/afternoon/evening, Mr. Ahmed. It\\'s a pleasure to see you.\" (Use the appropriate time of day)\\n*   \"Hello, Mr. Ahmed. I hope you\\'re having a good day.\"\\n*   \"It\\'s good to see you, Mr. Ahmed.\"\\n\\n**Slightly Less Formal (but still respectful):**\\n\\n*   \"Hello, Mr. Ahmed. How are you doing today?\"\\n*   \"Hi Mr. Ahmed, it\\'s nice to see you.\"\\n*   \"Hello, Mr. Ahmed. I hope everything is well.\"\\n\\n**If you know him well and have a more casual relationship:**\\n\\n*   \"Hi Ahmed, good to see you!\"\\n*   \"Hello Ahmed, how\\'s it going?\"\\n*   \"Hey Ahmed, nice to see you again.\"\\n\\n**If you know something specific about him or a shared experience:**\\n\\n*   \"Hello Mr. Ahmed, I hope you enjoyed [mention a recent event or topic you know he\\'s interested in].\"\\n*   \"Hi Mr. Ahmed, it\\'s good to see you. How was [mention something specific, like his weekend or a project]?\"\\n\\n**To choose the best option, consider:**\\n\\n*   **Your relationship with Mr. Ahmed:** Are you colleagues, acquaintances, friends, or in a professional setting?\\n*   **The context:** Is this a formal meeting, a casual encounter, or something else?\\n*   **Your usual way of addressing him:** Do you normally use his first name or last name?\\n\\n**Example:**\\n\\nIf you are colleagues and usually use his last name, a good option might be: \"Good morning, Mr. Ahmed. It\\'s a pleasure to see you.\"\\n\\nIf you are friends, you might say: \"Hey Ahmed, good to see you!\"\\n\\nChoose the greeting that feels most natural and appropriate for your specific situation.\\n',\n",
       " 'AI_Tool': 'Okay, here\\'s a message you can use to tell Ahmed about your new AI tool for Fiverr gig optimization:\\n\\n**Option 1: Short & Sweet (Good for a quick message)**\\n\\n> Hey Ahmed, just wanted to let you know about a new AI tool we\\'ve developed that can help you optimize your Fiverr gigs! It analyzes your gig and suggests improvements to help you rank higher and attract more clients. Check it out [link to your tool]!\\n\\n**Option 2: Slightly More Detailed (Good for an email or longer message)**\\n\\n> Hi Ahmed,\\n>\\n> I hope you\\'re doing well!\\n>\\n> I\\'m excited to share that we\\'ve just launched a new AI-powered tool specifically designed to help freelancers like you optimize their Fiverr gigs. This tool analyzes your gig title, description, tags, and even pricing, and provides data-driven suggestions to improve your visibility and attract more clients.\\n>\\n> It can help you:\\n>\\n> *   **Identify high-impact keywords:** Discover the best keywords to use in your gig.\\n> *   **Optimize your description:** Craft a compelling description that converts.\\n> *   **Improve your pricing strategy:** Find the sweet spot for your services.\\n> *   **Boost your overall ranking:** Get your gigs seen by more potential buyers.\\n>\\n> You can learn more and try it out here: [link to your tool]\\n>\\n> Let me know what you think!\\n>\\n> Best,\\n> [Your Name/Company Name]\\n\\n**Option 3: Focus on Benefits (Good for highlighting the value)**\\n\\n> Hey Ahmed,\\n>\\n> Are you looking for ways to get more out of your Fiverr gigs? We\\'ve created an AI tool that can help you do just that!\\n>\\n> Our tool analyzes your gigs and provides actionable insights to help you:\\n>\\n> *   **Get more visibility:** Rank higher in Fiverr search results.\\n> *   **Attract more clients:** Craft compelling gig descriptions that convert.\\n> *   **Save time and effort:** Stop guessing and start optimizing with data.\\n>\\n> Ready to take your Fiverr game to the next level? Check out our AI tool here: [link to your tool]\\n>\\n> Let me know if you have any questions!\\n>\\n> Best,\\n> [Your Name/Company Name]\\n\\n**Key things to remember when messaging Ahmed:**\\n\\n*   **Personalize it:** If you know Ahmed well, you can add a more personal touch.\\n*   **Include a clear call to action:** Tell him what you want him to do (e.g., \"Check it out,\" \"Try it now\").\\n*   **Provide a link:** Make it easy for him to access the tool.\\n*   **Be enthusiastic:** Show your excitement about the tool and its potential to help him.\\n*   **Be available for questions:** Let him know you\\'re there to help if he has any questions.\\n\\n**Before you send the message, make sure:**\\n\\n*   Your AI tool is ready and working properly.\\n*   You have a clear landing page or instructions for users.\\n*   You have a way to track usage and gather feedback.\\n\\nGood luck! Let me know if you\\'d like any variations on these messages.\\n',\n",
       " 'Follow_Up_Message': 'Okay, I need a little more context to give you the best follow-up question.  To help me, tell me:\\n\\n* **What tool are we talking about?** (e.g., a specific software, a physical tool, a process, a method)\\n* **What was the original question or task related to the tool?** (What was Ahmed using it for?)\\n* **What was Ahmed\\'s response or action?** (Did he say he was done? Did he encounter a problem? Did he provide some feedback?)\\n\\nOnce I have this information, I can craft a relevant and helpful follow-up question.\\n\\n**For example, you could say:**\\n\\n* \"Ahmed was using the new project management software. He said he finished setting up the tasks. What\\'s a good follow-up question?\"\\n* \"Ahmed was using the power drill. He said he was having trouble with the bit slipping. What\\'s a good follow-up question?\"\\n* \"Ahmed was following the new onboarding process. He said he completed step 3. What\\'s a good follow-up question?\"\\n\\nLooking forward to helping you!\\n'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template('Say Personalized hello to Mr. {name}')\n",
    "chain_one = LLMChain(llm = model, prompt = first_prompt, output_key = 'Greetings')\n",
    "\n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_template('Tell the {name} about there new AI tool that help freelancers to optimize there fiverr gigs using our AI tool')\n",
    "chain_two = LLMChain(llm = model, prompt = second_prompt, output_key = 'AI_Tool')\n",
    "\n",
    "third_prompt = ChatPromptTemplate.from_template('Ask a follow up for the tool to the {name}')\n",
    "chain_three = LLMChain(llm = model, prompt = third_prompt, output_key = 'Follow_Up_Message')\n",
    "\n",
    "overall_chains = SequentialChain(\n",
    "    chains = [chain_one, chain_two, chain_three], \n",
    "    input_variables = [\"name\"],\n",
    "    output_variables = ['Greetings', 'AI_Tool', 'Follow_Up_Message'],\n",
    "    verbose = True)\n",
    "\n",
    "\n",
    "name = 'Ahmed'\n",
    "overall_chains(name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerScience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerScience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['physics: Good for answering questions about physics', 'math: Good for answering math questions', 'History: Good for answering history questions', 'computer science: Good for answering computer science questions']\n",
      "physics: Good for answering questions about physics\n",
      "math: Good for answering math questions\n",
      "History: Good for answering history questions\n",
      "computer science: Good for answering computer science questions\n"
     ]
    }
   ],
   "source": [
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=model, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "print(destinations)\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "print(destinations_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if random question is asked then it will be routed to the chain that is best suited to answer the question\n",
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=model, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(model, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Okay, let\\'s talk about black body radiation.\\n\\nImagine an object that absorbs *all* electromagnetic radiation that hits it, regardless of the frequency or angle. That\\'s a \"black body\" â€“ it doesn\\'t reflect any light, hence it appears black. Now, even though it absorbs all radiation, it also *emits* radiation. This emitted radiation is what we call black body radiation.\\n\\nHere\\'s the key:\\n\\n*   **Temperature Dependence:** The spectrum (the distribution of wavelengths) of the emitted radiation depends *only* on the temperature of the black body. Hotter objects emit more radiation and at shorter wavelengths (higher frequencies).\\n*   **Universal Spectrum:** The specific shape of the black body radiation spectrum is universal. It doesn\\'t depend on the material the black body is made of, only its temperature.\\n*   **Idealization:** A perfect black body is an idealization. Real objects aren\\'t perfect absorbers or emitters, but many objects approximate black body behavior, especially in certain frequency ranges.\\n\\n**In simpler terms:**\\n\\nThink of a piece of metal. When you heat it up, it starts to glow. First, it might glow a dull red, then as it gets hotter, it becomes orange, then yellow, and eventually white-hot. This change in color and intensity is a direct result of black body radiation. The hotter the metal, the more light it emits and the shorter the wavelengths of that light.\\n\\n**Why is it important?**\\n\\nBlack body radiation is a fundamental concept in physics. It was crucial in the development of quantum mechanics because classical physics failed to explain the observed black body spectrum. It also has practical applications, such as:\\n\\n*   **Understanding stars:** Stars emit radiation that approximates black body radiation, allowing us to determine their surface temperatures.\\n*   **Infrared imaging:** Thermal cameras detect infrared radiation emitted by objects, which is a form of black body radiation.\\n*   **Lighting:** Incandescent light bulbs emit light based on black body radiation principles.\\n\\nSo, in short, black body radiation is the thermal electromagnetic radiation emitted by an ideal object that absorbs all incoming radiation. The spectrum of this radiation is determined solely by the object\\'s temperature.\\n\\nDoes that make sense? Let me know if you have any other questions.\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'what is 2 + 2'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Okay, I can definitely handle this! Let\\'s break down the problem \"2 + 2\":\\n\\n**1. Identify the Operation:**\\n\\n* The \"+\" symbol indicates addition. This means we need to combine the two numbers.\\n\\n**2. Identify the Numbers:**\\n\\n* We have two instances of the number \"2\".\\n\\n**3. Perform the Addition:**\\n\\n*  Imagine you have 2 objects, and then you get 2 more. How many do you have in total? You would have 4.\\n\\n**4. State the Answer:**\\n\\n* Therefore, 2 + 2 = 4\\n\\n**Final Answer:**\\n\\nThe answer to the question \"what is 2 + 2\" is **4**.\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'Why does every cell in our body contain DNA?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's a great question! Here's the concise answer:\\n\\nEvery cell in your body contains DNA because **DNA is the blueprint for life.** It holds all the instructions needed to build and operate a cell, and therefore, the entire organism. \\n\\nThink of it like this:\\n\\n*   **DNA is the master instruction manual:** It contains all the genes that code for proteins, which are the workhorses of the cell.\\n*   **Cells are like individual factories:** Each cell needs its own copy of the instructions to function correctly.\\n*   **Cell division:** When cells divide, they need to pass on the instructions to the new cells, which is why DNA is replicated and distributed to each daughter cell.\\n\\nSo, every cell needs its own copy of the DNA to:\\n\\n1.  **Carry out its specific functions:** Different cells have different jobs (e.g., muscle cells vs. nerve cells), and the DNA dictates which proteins they produce to perform those jobs.\\n2.  **Maintain itself:** DNA contains the instructions for all the proteins needed for cell maintenance and repair.\\n3.  **Reproduce:** When cells divide, they need to pass on the genetic information to the new cells.\\n\\nIn short, DNA is the fundamental information carrier, and every cell needs it to exist and function.\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'tell me a joke'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Okay, here's a joke for you:\\n\\nWhy don't scientists trust atoms?\\n\\n... Because they make up everything!\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run('tell me a joke')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
